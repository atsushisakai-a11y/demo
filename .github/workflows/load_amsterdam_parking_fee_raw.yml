name: 1-2.Amsterdam Parking Fee JSON into BigQuery (RAW)

on:
  workflow_dispatch:

jobs:
  load-parking-fee-json:
    runs-on: ubuntu-latest

    steps:
      # ---------------------------------------------------------------------
      # 1. Checkout repository
      # ---------------------------------------------------------------------
      - name: Checkout repository
        uses: actions/checkout@v3

      # ---------------------------------------------------------------------
      # 2. Decode GCP service account key
      # ---------------------------------------------------------------------
      - name: Decode GCP service account key
        run: |
          echo "${{ secrets.GCP_SA_KEY_B64 }}" | base64 --decode > $HOME/key.json

      # ---------------------------------------------------------------------
      # 3. Authenticate with gcloud
      # ---------------------------------------------------------------------
      - name: Authenticate with gcloud
        run: |
          gcloud auth activate-service-account --key-file=$HOME/key.json
          gcloud config set project grand-water-473707-r8
          echo "GOOGLE_APPLICATION_CREDENTIALS=$HOME/key.json" >> $GITHUB_ENV

      # ---------------------------------------------------------------------
      # 4. Find latest JSON file in GCS
      # ---------------------------------------------------------------------
      - name: Find latest parking fee JSON in GCS
        id: findfile
        run: |
          FILE=$(gsutil ls gs://standard_parking_price/partking_fee_amsterdam_*.json | sort | tail -n 1)
          if [ -z "$FILE" ]; then
            echo "❌ No parking fee JSON file found in GCS."
            exit 1
          fi
          echo "latest_file=$FILE" >> $GITHUB_OUTPUT
          echo "Found JSON file: $FILE"

      # ---------------------------------------------------------------------
      # 5. Download JSON file
      # ---------------------------------------------------------------------
      - name: Download JSON file
        run: |
          gsutil cp "${{ steps.findfile.outputs.latest_file }}" raw_geo.json
          echo "Downloaded raw_geo.json"

      # ---------------------------------------------------------------------
      # 6. Create robust JSON → NDJSON conversion script
      # ---------------------------------------------------------------------
      - name: Create conversion script
        run: |
          echo "import json, re" > convert_geojson.py

          echo "def fix_invalid_keys(obj):" >> convert_geojson.py
          echo "    if isinstance(obj, dict):" >> convert_geojson.py
          echo "        valid = {}" >> convert_geojson.py
          echo "        invalid_list = []" >> convert_geojson.py
          echo "        for k, v in obj.items():" >> convert_geojson.py
          echo "            # SPECIAL CASE: GeoJSON polygon (nested arrays!) → convert to STRING" >> convert_geojson.py
          echo "            if k == 'location':" >> convert_geojson.py
          echo "                valid['location_json'] = json.dumps(v)" >> convert_geojson.py
          echo "                continue" >> convert_geojson.py

          echo "            # VALID BigQuery key?" >> convert_geojson.py
          echo "            if re.match(r'^[A-Za-z_][A-Za-z0-9_]*$', str(k)):" >> convert_geojson.py
          echo "                valid[k] = fix_invalid_keys(v)" >> convert_geojson.py
          echo "            else:" >> convert_geojson.py
          echo "                invalid_list.append({'key': k, 'value': fix_invalid_keys(v)})" >> convert_geojson.py

          echo "        if invalid_list:" >> convert_geojson.py
          echo "            valid['__invalid_keys__'] = invalid_list" >> convert_geojson.py
          echo "        return valid" >> convert_geojson.py

          echo "    elif isinstance(obj, list):" >> convert_geojson.py
          echo "        return [fix_invalid_keys(i) for i in obj]" >> convert_geojson.py

          echo "    else:" >> convert_geojson.py
          echo "        return obj" >> convert_geojson.py


          echo "with open('raw_geo.json') as f:" >> convert_geojson.py
          echo "    data = json.load(f)" >> convert_geojson.py

          echo "records = []" >> convert_geojson.py
          echo "for zone_id, block in data.items():" >> convert_geojson.py
          echo "    fixed = fix_invalid_keys(block)" >> convert_geojson.py
          echo "    fixed['zone_id'] = zone_id" >> convert_geojson.py
          echo "    records.append(fixed)" >> convert_geojson.py

          echo "with open('parking_fee.ndjson', 'w') as out:" >> convert_geojson.py
          echo "    for r in records:" >> convert_geojson.py
          echo "        out.write(json.dumps(r) + '\\n')" >> convert_geojson.py

          echo "print('Converted', len(records), 'zones → parking_fee.ndjson')" >> convert_geojson.py

      # ---------------------------------------------------------------------
      # 7. Convert JSON → NDJSON
      # ---------------------------------------------------------------------
      - name: Convert JSON to NDJSON
        run: |
          python3 convert_geojson.py
          echo "NDJSON Preview:"
          head -n 5 parking_fee.ndjson

      # ---------------------------------------------------------------------
      # 8. Ensure RAW dataset exists
      # ---------------------------------------------------------------------
      - name: Ensure RAW dataset exists
        run: |
          bq --location=EU mk --dataset grand-water-473707-r8:raw || echo "Dataset already exists"

      # ---------------------------------------------------------------------
      # 9. Load NDJSON into BigQuery
      # ---------------------------------------------------------------------
      - name: Load NDJSON into BigQuery RAW table
        run: |
          echo "Loading NDJSON into BigQuery..."
          bq load \
            --source_format=NEWLINE_DELIMITED_JSON \
            --autodetect \
            raw.raw_parking_fee_amsterdam \
            parking_fee.ndjson
          echo "✔ Successfully loaded into raw.raw_parking_fee_amsterdam"
