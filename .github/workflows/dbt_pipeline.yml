name: Run dbt Pipeline

on:
  workflow_dispatch:
    inputs:
      dataset:
        description: "Target BigQuery dataset (staging, dwh, marts)"
        required: false
        default: "staging"
        type: string
      model_name:
        description: "Optional: Run a specific dbt model"
        required: false
        type: string

jobs:
  run-dbt-pipeline:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      pages: write
      id-token: write

    steps:
      # -------------------------
      # 1. CHECKOUT REPO
      # -------------------------
      - name: Checkout repository
        uses: actions/checkout@v3

      # -------------------------
      # 2. SETUP PYTHON + INSTALL DBT
      # -------------------------
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Install dbt-bigquery
        run: |
          pip install --upgrade pip
          pip install dbt-bigquery

      # -------------------------
      # 3. GCP SERVICE ACCOUNT
      # -------------------------
      - name: Decode GCP service account key
        run: |
          echo "${{ secrets.GCP_SA_KEY_B64 }}" | base64 --decode > key.json

      - name: Create dbt profiles.yml
        run: |
          mkdir -p ~/.dbt
          cat > ~/.dbt/profiles.yml << EOF
          demo:
            target: prod
            outputs:
              prod:
                type: bigquery
                method: service-account
                project: grand-water-473707-r8
                keyfile: key.json
                dataset: staging
                threads: 4
                location: EU
          EOF

      # -------------------------
      # DEBUG WORKING DIR
      # -------------------------
      - name: Confirm working directory
        run: |
          echo "PWD: $(pwd)"
          echo "--- Repo structure ---"
          ls -R .

      # -------------------------
      # 4. RUN DBT PIPELINE
      # -------------------------
      - name: Run dbt build (full pipeline)
        if: ${{ github.event.inputs.model_name == '' }}
        env:
          DBT_DATASET_OVERRIDE: ${{ github.event.inputs.dataset }}
        run: |
          echo "Running dbt pipeline into dataset: $DBT_DATASET_OVERRIDE"
          dbt build

      - name: Run single dbt model
        if: ${{ github.event.inputs.model_name != '' }}
        env:
          DBT_DATASET_OVERRIDE: ${{ github.event.inputs.dataset }}
        run: |
          MODEL="${{ github.event.inputs.model_name }}"
          echo "Running dbt model: $MODEL into dataset: $DBT_DATASET_OVERRIDE"
          dbt run --select "$MODEL"

      # -------------------------
      # 5. GENERATE DBT DOCS
      # -------------------------
      - name: Generate dbt docs
        env:
          DBT_DATASET_OVERRIDE: ${{ github.event.inputs.dataset }}
        run: |
          echo "Generating dbt docs for dataset: $DBT_DATASET_OVERRIDE"
          dbt docs generate

      # -------------------------
      # 6. PREPARE DOCS FOR PAGES
      # -------------------------
      - name: Prepare docs for GitHub Pages
        run: |
          mkdir -p public
          cp -r target/* public/

      # -------------------------
      # 7. UPLOAD ARTIFACT
      # -------------------------
      - name: Upload docs artifact
        uses: actions/upload-pages-artifact@v3
        with:
          name: github-pages
          path: public

      # -------------------------
      # 8. DEPLOY DOCS TO GITHUB PAGES
      # -------------------------
      - name: Deploy to GitHub Pages
        uses: actions/deploy-pages@v4
