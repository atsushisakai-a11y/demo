name: 1-1.ParkBee HAR → JSON → raw_parkbee_garages

on:
  workflow_dispatch:
    inputs:
      har_filename:
        description: "HAR file name in GCS (e.g., parkbee_2025-01-18.har)"
        required: true
        type: string

jobs:
  har-to-bigquery:
    runs-on: ubuntu-latest

    steps:
      # -------------------------------------------------
      # 1. Checkout repository
      # -------------------------------------------------
      - name: Checkout repository
        uses: actions/checkout@v3

      # -------------------------------------------------
      # 2. Setup Python
      # -------------------------------------------------
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      # -------------------------------------------------
      # 3. Decode GCP service account key
      # -------------------------------------------------
      - name: Decode GCP service account key
        run: echo "${{ secrets.GCP_SA_KEY_B64 }}" | base64 --decode > $HOME/key.json

      # -------------------------------------------------
      # 4. Authenticate with gcloud
      # -------------------------------------------------
      - name: Authenticate with gcloud
        run: |
          gcloud auth activate-service-account --key-file=$HOME/key.json
          gcloud config set project grand-water-473707-r8

      # -------------------------------------------------
      # 5. Download HAR from GCS
      # -------------------------------------------------
      - name: Download HAR file from GCS
        run: |
          echo "Downloading HAR file..."
          gsutil cp gs://parkbee-har-data/${{ github.event.inputs.har_filename }} .
          echo "Downloaded: ${{ github.event.inputs.har_filename }}"

      # -------------------------------------------------
      # 6. Run extraction script
      # -------------------------------------------------
      - name: Run HAR extraction script
        run: |
          echo "Extracting garages from HAR..."
          python scripts/extract_parkbee.py ${{ github.event.inputs.har_filename }}

      # -------------------------------------------------
      # 7. Upload JSON to GCS
      # -------------------------------------------------
      - name: Upload JSON to GCS
        run: |
          JSON_FILE=$(ls parkbee_garages_*.json)
          echo "Uploading JSON file $JSON_FILE to GCS..."
          gsutil cp $JSON_FILE gs://parkbee-raw-data/$JSON_FILE
          echo "Uploaded JSON: $JSON_FILE"

      # -------------------------------------------------
      # 8. Load JSON → temporary table
      # -------------------------------------------------
      - name: Load JSON into BigQuery (temporary table)
        run: |
          JSON_FILE=$(ls parkbee_garages_*.json)
          echo "Dropping previous temp table..."
          bq rm -f -t raw.new_parkbee_garages_tmp || true

          echo "Loading JSON into raw.new_parkbee_garages_tmp..."
          bq load \
            --source_format=NEWLINE_DELIMITED_JSON \
            --autodetect \
            raw.new_parkbee_garages_tmp \
            gs://parkbee-raw-data/$JSON_FILE

      # -------------------------------------------------
      # 9. Normalize schema → match raw table
      # -------------------------------------------------
      - name: Normalize temp schema
        run: |
          echo "Normalizing schema..."
          bq query --use_legacy_sql=false "
          CREATE OR REPLACE TABLE \`raw.new_parkbee_garages_tmp\` AS
          SELECT
            id,
            name,
            latitude,
            longitude,
            address,
            pricingAndAvailability,
            scrape_datetime,
            parking_from,
            parking_to,
            parking_duration_hours,
            hourly_price
          FROM \`raw.new_parkbee_garages_tmp\`;
          "

      # -------------------------------------------------
      # 10. MERGE (UPSERT) → append new data only
      # -------------------------------------------------
      - name: Append (MERGE) into raw.raw_parkbee_garages
        run: |
          echo "Appending new data into raw.raw_parkbee_garages via MERGE..."
          bq query --use_legacy_sql=false "
          MERGE INTO \`raw.raw_parkbee_garages\` AS target
          USING \`raw.new_parkbee_garages_tmp\` AS source
          ON target.id = source.id
          AND target.scrape_datetime = source.scrape_datetime
          WHEN NOT MATCHED THEN
            INSERT (
              id,
              name,
              latitude,
              longitude,
              address,
              pricingAndAvailability,
              scrape_datetime,
              parking_from,
              parking_to,
              parking_duration_hours,
              hourly_price
            )
            VALUES (
              source.id,
              source.name,
              source.latitude,
              source.longitude,
              source.address,
              source.pricingAndAvailability,
              source.scrape_datetime,
              source.parking_from,
              source.parking_to,
              source.parking_duration_hours,
              source.hourly_price
            );
          "
          echo "Historical data preserved — new rows appended."

      # -------------------------------------------------
      # 11. Cleanup temp table
      # -------------------------------------------------
      - name: Cleanup
        if: always()
        run: |
          echo "Removing temporary table..."
          bq rm -f -t raw.new_parkbee_garages_tmp || true
          echo "Cleanup complete."
